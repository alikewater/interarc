

子线程中对变量的改变可以在主线程中反映出来，主线程中对变量的改变在子线程中不可见。子线程中对同一实例对象的成员变量
的改变可见。


 1.基本的多线程并发编程……
    1.1 线程概念
      线程构造方式：传递一个Thread的实例，或者传递一个实现Runnable接口的对象，并发访问的代码段可以是run方法本身，
      也可以是run方法中调用目标对象的相关方法。
      线程发生异常如果不捕获的话，JVM会自动停止线程的后续工作。
      线程异常发生的处理方式：  日志记录后继续执行，或者回滚已经执行的内容。
    1.2 线程同步
      synchronized 线程同步锁重量级锁。锁是基于具体对象实例实现的，对象头部包含了锁的信息。具体又分为类锁和对象锁，
      类锁锁的是类class对象，对象锁锁的是具体class对象实例化出来的类的实例。sychronized结合notify和wait实现线程见同步。wait调用
      释放锁，notify调用不释放锁，因此notify实现同步不具备实时性。
      volatile关键字线程可见性，不保证原子性。结合volatile和CAS(Compare and Set)保证原子性。AtomicXXX数据类型通过该方法保证原子性。
      AQS通过采用CAS结合CLH队列实现高效率的线程并发控制，JUC包中的RetrenLock/Condition/CountDownLunch/Semaphore都属于这一体系。


      volatile的应用环境，判断标志（可见性），double check（可见性和有序性）

      线程同步和单例模式，单例模式实现方式：1.静态内部类 2.double check 懒加载

   1.3 同步类容器和并发类容器
      线程安全的容器 Vector替代List， HashTable替换HashMap.

      立足于多线程，高并发的容器：
      concurrentHashMap 和CopyOnWrite容器

      ConcurrentSkipListMap

      ConcurrentHashMap 通过分段将锁粒度细化。segment设计使得整个容器分为n个小区域。每个小区域为一个锁单元，最高支持16个段
      CopyOnWriteArrayList 和CopyOnWriteArraySet.当我按一个容器进行写操作时，不是直接操作当前容器，现将当前容器进行拷贝，复制出
      一个和元容器一样的副本，在新的副本上进行操作，然后再切换容器指向。实现了读写分离的思想，主要用于读多写少的场景。写太多时，复制的
      负担过重，不适用。多个写不能并发，是加锁实现的

   1.4 队列
      Queue:
      高性能队列(非阻塞)： ConcurrentLinkQueue 基于链接节点的无界队列，不允许null元素  add和offer加入元素，这两个方法在该类中无区别。
       pull和peak取出元素，前者删除元素，后者不会.
      阻塞队列：BlockingQueue

      ArrayBlockingQueue 基于数组的阻塞队列实现，没有实现读写分离，读写段不能完全同时进行，先进先出，有界队列

      LinkedBlockingQueue 基于链表实现的阻塞队列，内部由链表实现的存储，实现了读写分离（采用了读写分离的两个锁），无界队列

      SynchronousQueue 一种没有缓冲的队列，生产者生产的数据直接被消费者消费,这种队列只先进行take等待，再往里面加add元素，立即获得处理
      peek poll 不阻塞，没有元素返回空，add不允许直接添加元素，需要有take调用在先，否则抛出异常。offer放入无阻塞，没有take调用在先时不成功。
      put阻塞放入，没有take调用时，一直尝试添加。

      PriorityBlockingQueue 基于优先级的队列，无界队列，公平锁

      DelayQueue:带有延时的queue,元素要实现Delayed接口，用于时间排序和获取时间。适用于根据特定延时优先级进行元素获取。

      Dequeue 允许在队列的头部和尾部入队和出队
          LinkedBlockingDequeue 一种Dequeue的实现，没有实现读写分离，其高并发性能低于其他的BlockingQueue，同时也低于
          ConcurrentLinkedQueue 高并发的Deque实现
          
   1.5 线程设计模式
     Master--Worker模式: Master维护工作队列、Woker容器和结果收集容器。 Worker持有工作队列和结果收集容器，从工作队列获取任务执行，并存储结果到
     结果收集容器。
     Futrue模式 ，调用之后立即返回一个Future包装对象，然后后台启动新线程抓去真实数据填充到Future对象，Futrue对象内部的容器负责进行同步协作。
     生产者--消费者模式
     解耦和同步的使用。通过内部的容器（Queue）进行生产和消费段的解耦合，同时利用容器的存取同步实现
   
   1.6 线程池/多任务执行框架

       Excutors创建线程的方法：
               Executors.newFixedThreadPool();//创建固定数量的线程池，有空闲线程，立即执行任务，没有空闲线程则存在队列中，队列存储满了，拒绝服务
               Executors.newCachedThreadPool();//创建缓冲线程池，可调整线程池大小，有空闲线程可直接执行任务，没有空闲线程则创建线程执行任务，空闲线程慢60后自动回收
               Executors.newScheduledThreadPool();//创建调度线程池，返回一个ScheduledExecutorService 用以执行定时任务，该线程池可指定线程数量。
               Executors.newSingleThreadExecutor();//创建只有一个线程的线程池，空闲则执行任务，不空闲则任务入队列

               以上线程池都是通过
               public ThreadPoolExecutor(int corePoolSize,//核心线程数，初始化的线程数
                                             int maximumPoolSize,//最大线程数量
                                             long keepAliveTime,//线程存活时间
                                             TimeUnit unit,//时间单位
                                             BlockingQueue<Runnable> workQueue,//线程工作队列
                                             ThreadFactory threadFactory,//线程创建工厂
                                             RejectedExecutionHandler handler) //任务提交的拒绝策略


               创建的，其中重要参数参数分别表示初始化的线程数量，最大线程数量，和任务缓冲队列

                * 在使用有界队列时，若有新的任务需要执行，如果线程池实际线程数小于corePoolSize，则优先创建线程，
                * 若大于corePoolSize，则会将任务加入队列，
                * 若队列已满，则在总线程数不大于maximumPoolSize的前提下，创建新的线程，
                * 若线程数大于maximumPoolSize，则执行拒绝策略。或其他自定义方式。

                在使用无界队列时，除非资源耗尽，否则不存在任务入队失败的情况。新任务到来如果实际线程数小于corePoolSize则创建新
                线程，如果线程数量大于corePoolSize，那么入队。maxSize对于无界队列来说无效。

                线程池的拒绝策略：
                AbortPolicy： 直接抛出异常
                CallerRunsPolicy： 将当前被丢弃的任务在调用者线程中执行
                DiscardOldestPolicy: 丢弃最老的任务
                DiscardPolicy:直接丢弃不予执行

                自定义拒绝策略：记录日志，稍后跑批处理（Apache HttpClient---一种http请求的操作客户端）

   1.7 JUC Concurrent包工具类

        Feture模式实现的使用：FutrueTask与Feture,实际任务逻辑采用一个Callable<T>的实现类完成。并以此狗仔一个FetureTask实例。
        采用线程执行该FutureTask。

        CountDownLunch，当条件达成，用于一次性通知等待的线程继续运行。使用场景主线程等待子线程初始化完成，或者并发测试中多个线程
        一同启动。主要await()用于等待，countdown()用于条件计数，条件计数达到初始化数量即为条件达成。
        CycleBaCycleBarrier：循环使用当wait()调用次数达到屏障初始化次数，条件达成，调用wait的线程自动继续。没有显示的notify类操作

        Semaphore信号量，用于同时访问的并发数量限制  aquire() 和release()进行获取和释放

    高并发实现：1. 网络端
              2. 服务后端：
               业务微服务化，业务分布式部署实现分流。每个业务进行Nginx负载均衡
               Nginx进行分流负载均衡，Redies限流，缓存策略，提高读性能，服务降级，锁
               Semaphore信号量可以作为一种限流措施，一种几个线程可以同时拥有的锁，实现了锁的并发度控制

               并发容量评估：
               峰值QPS = (总PV*80%)/(60*60*24*20%) 百分之80的流量发生在百分之20的时间内

               机器数量 =总的峰值QPS/单机压测的到的最大QPS

               QPS:
               每秒查询率(Query Per Second) ,每秒的响应请求数，也即是最大吞吐能力。
               QPS = req/sec = 请求数/秒
               QPS统计方式 [一般使用 http_load 进行统计]
               QPS = 总请求数 / ( 进程总数 * 请求时间 )
               QPS: 单个进程每秒请求服务器的成功次数

               峰值QPS:
               原理：每天80%的访问集中在20%的时间里，这20%时间叫做峰值时间
               公式：( 总PV数 * 80% ) / ( 每天秒数 * 20% ) = 峰值时间每秒请求数(QPS)

               PV:
               访问量即Page View, 即页面浏览量或点击量，用户每次刷新即被计算一次
               单台服务器每天PV计算
               公式1：每天总PV = QPS * 3600 * 6
               公式2：每天总PV = QPS * 3600 * 8

               UV:
               独立访客即Unique Visitor,访问您网站的一台电脑客户端为一个访客。00:00-24:00内相同的客户端只被计算一次
               服务器数量：
               机器：峰值时间每秒QPS / 单台机器的QPS = 需要的机器
               机器：ceil( 每天总PV / 单台服务器每天总PV )

               并发数：
               并发用户数是指系统可以同时承载的正常使用系统功能的用户的数量

               吐吞量：
               吞吐量是指系统在单位时间内处理请求的数量
               响应时间（RT):
               响应时间是指系统对请求作出响应的时间

               例子：
               每天300w PV 的在单台机器上，这台机器需要多少QPS？
               答：( 3000000 * 0.8 ) / (86400 * 0.2 ) = 139 (QPS)
               如果一台机器的QPS是58，需要几台机器来支持？
               答：139 / 58 = 3
               ---------------------

      Lock对象：重入锁和读写锁，嗅探锁定，多路分支（Condition）

      Lock的Condition用于线程间同步，比Sychronized更加灵活。直接Synchronized修饰方法默认在类的方法中只能使用
      类实例对象的自身锁定功能。如果是采用对象锁，不能实现多路分支。

      ReentrantReadWriteLock:里面两把锁，读锁和写锁。 读读共享，读写互斥，写写互斥。 在读多写少的场景中，提高并发访问速度。
      但是写操作较多的时候，基本还是互斥的操作，因此并不比重入锁效率高。





